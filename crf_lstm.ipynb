{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF+LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras 2.2.4\n",
    "\n",
    "tensorflow 1.13\n",
    "\n",
    "pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vocab_path = \"CRF/data/char_vocabs.txt\" # 字典文件\n",
    "train_data_path = 'data/train_data/train_data_000' # 训练数据\n",
    "#train_data_path = './data/train_data' # 训练数据\n",
    "test_data_path = 'data/train_data/train_data_000' # 测试数据\n",
    "\n",
    "special_words = ['<PAD>', '<UNK>'] # 特殊词表示\n",
    "\n",
    "# \"BIO\"标记的标签\n",
    "#label2idx = {\"O\": 0,\n",
    "#             \"B-PER\": 1, \"I-PER\": 2,\n",
    "#             \"B-LOC\": 3, \"I-LOC\": 4,\n",
    "#             \"B-ORG\": 5, \"I-ORG\": 6\n",
    "#            }\n",
    "label2idx = {'O': 0,\n",
    "             'DISEASE': 1, 'DISEASE_GROUP': 2,\n",
    "             'DRUG_DOSAGE': 3, 'DRUG_EFFICACY': 4,\n",
    "             'DRUG_INGREDIENT': 5, 'DRUG_TASTE': 6,\n",
    "             'FOOD_GROUP':7, 'PERSON_GROUP':8,\n",
    "             'SYMPTOM':9, 'SYNDROME':10\n",
    "            }\n",
    "\n",
    "# 索引和BIO标签对应\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "\n",
    "# 读取字符词典文件\n",
    "with open(char_vocab_path, \"r\", encoding=\"utf8\") as fo:\n",
    "    char_vocabs = [line.strip() for line in fo]\n",
    "char_vocabs = special_words + char_vocabs\n",
    "\n",
    "# 字符和索引编号对应\n",
    "idx2vocab = {idx: char for idx, char in enumerate(char_vocabs)}\n",
    "vocab2idx = {char: idx for idx, char in idx2vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练语料\n",
    "def read_corpus(corpus_path, vocab2idx, label2idx):\n",
    "    with open(corpus_path, encoding='utf-8') as fr:\n",
    "        lines = fr.readlines()\n",
    "\n",
    "    sent_, tag_ = [], []\n",
    "    for letter in lines:\n",
    "        [char,label,_] = re.split('\\t|\\n',letter)\n",
    "        sent_.append(char)\n",
    "        tag_.append(label)\n",
    "\n",
    "    sent_ids = [vocab2idx[char] if char in vocab2idx else vocab2idx['<UNK>'] for char in sent_]\n",
    "    tag_ids = [label2idx[label] if label in label2idx else 0 for label in tag_]\n",
    "    return sent_ids, tag_ids\n",
    "\n",
    "# 加载训练集\n",
    "train_datas, train_labels = read_corpus(train_data_path, vocab2idx, label2idx)\n",
    "# 加载测试集\n",
    "test_datas, test_labels = read_corpus(test_data_path, vocab2idx, label2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datas = []\n",
    "train_labels = []\n",
    "for i in range(1000):\n",
    "    train_data_path_i = 'data/train_data/train_data_%03d'%i\n",
    "    train_datas_i, train_labels_i = read_corpus(train_data_path_i, vocab2idx, label2idx)\n",
    "    train_datas.append(train_datas_i)\n",
    "    train_labels.append(train_labels_i)\n",
    "    #if i%10==0:\n",
    "    #    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datas = train_datas\n",
    "test_labels = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 589, 2644, 451, 5801, 5844, 5253, 966, 2953, 5253, 406, 3769, 182, 2659, 998, 4719, 451, 5801, 3647, 4101, 5980, 4717, 2178, 4793, 3900, 4463, 4702, 2008, 2494, 218, 6267, 3903, 2022, 1357, 6802, 2377, 6573, 1374, 5253, 1635, 6756, 3903, 5253, 4435, 5169, 3900, 911, 6009, 6802, 4539, 4020, 1635, 6756, 651, 5253, 2545, 6214, 966, 5253, 3160, 1357, 6040, 2545, 6214, 182, 0, 589, 2644, 6315, 3383, 4392, 2770, 406, 3769, 182, 2659, 998, 868, 1338, 719, 6315, 6756, 1534, 1588, 6007, 6009, 6802, 1338, 6573, 1367, 6756, 1534, 1588, 2288, 2494, 966, 6315, 287, 5988, 911, 6009, 6802, 723, 3556, 651, 3648, 723, 2065, 2654, 3903, 2994, 3630, 1338, 1363, 182, 0, 589, 2644, 463, 4669, 406, 3769, 182, 2659, 998, 868, 2276, 2223, 32, 12, 3020, 1297, 785, 280, 4377, 2178, 4793, 3903, 2000, 2002, 4669, 2327, 376, 1367, 6756, 5528, 228, 5738, 3020, 5983, 966, 5528, 4934, 5738, 3020, 5983, 504, 3903, 782, 6573, 6817, 1338, 719, 1192, 3022, 765, 4084, 2178, 4793, 2118, 2002, 4669, 2327, 1591, 1367, 6756, 3903, 2008, 5169, 3900, 966, 3900, 5169, 3900, 911, 6009, 182, 0, 589, 2644, 1338, 1903, 566, 3827, 406, 3769, 182, 2659, 998, 4719, 2377, 6573, 2954, 1809, 1635, 6756, 1622, 5253, 242, 4084, 4352, 3903, 3246, 6276, 5843, 1853, 966, 2223, 398, 1913, 2157, 4463, 4702, 3903, 6009, 6802, 451, 5801, 30, 4463, 4702, 850, 2223, 830, 684, 3383, 891, 3903, 659, 5296, 1338, 2974, 6802, 1338, 719, 1830, 6756, 4716, 4761, 2288, 2494, 6817, 1338, 1903, 1635, 6756, 4760, 4747, 1770, 1175, 4463, 4702, 902, 1175, 6666, 4435, 4463, 4702, 3903, 4719, 715, 182, 0, 589, 2644, 2223, 3418, 406, 3769, 182, 2659, 998, 4719, 2217, 680, 1778, 5531, 3092, 2178, 4793, 1635, 6756, 4635, 1866, 4687, 4688, 6802, 2217, 680, 5358, 842, 4993, 4715, 2178, 4793, 3903, 1367, 6756, 5640, 4687, 4688, 843, 1367, 6756, 2820, 3680, 4661, 4872, 4687, 3903, 1913, 2157, 6802, 274, 4719, 2217, 680, 4584, 3778, 1297, 4437, 4500, 4392, 2178, 4793, 4760, 4747, 3254, 651, 3212, 242, 3900, 4463, 4702, 2008, 2494, 3903, 1338, 1363, 182, 0, 0, 886, 2706, 211, 2954, 4955, 229, 6312, 1196, 2644, 6268, 580, 876, 0, 0, 5269, 3009, 592, 5253, 6802, 5483, 4471, 2953, 1803, 182, 3769, 288, 3009, 5253, 235, 5133, 6802, 5719, 398, 3880, 1899, 6802, 4755, 4774, 5985, 5740, 6802, 2643, 4471, 6009, 1637, 181, 891, 6133, 6802, 1803, 218, 0, 886, 2706, 211, 2954, 4955, 229, 6312, 1196, 2644, 6268, 580, 876, 0, 0, 857, 2646, 182, 211, 2937, 23, 565, 6802, 211, 2535, 15, 2937, 6817, 2161, 1629, 4955, 247, 719, 5824, 6009, 1874, 3025, 3305, 891, 2646, 182, 0, 0, 247, 688, 7, 1367, 5200, 247, 8, 0, 0, 1537, 1412, 4144, 3769, 182, 0, 0, 1367, 5200, 247, 2990, 247, 6007, 23, 565, 0, 0, 1219, 2646, 3769, 2659, 998, 2654, 6214, 6802, 1408, 2708, 2102, 679, 219, 5824, 6802, 5341, 1655, 1974, 934, 5434, 776, 1788, 2161, 4955, 1788, 182, 2065, 620, 4394, 2000, 868, 563, 515, 2953, 424, 3769, 6802, 1957, 5341, 2545, 679, 776, 6275, 1648, 5435, 182, 0, 3939, 694, 1643, 2657, 2818, 4393, 679, 2659, 998, 3903, 219, 4836, 846, 1842, 182, 0, 0, 589, 2644, 451, 5801, 5844, 5253, 966, 2953, 5253, 406, 3769, 182, 2659, 998, 4719, 451, 5801, 3647, 4101, 5980, 4717, 2178, 4793, 3900, 4463, 4702, 2008, 2494, 218, 6267, 3903, 2022, 1357, 6802, 2377, 6573, 1374, 5253, 1635, 6756, 3903, 5253, 4435, 5169, 3900, 911, 6009, 6802, 4539, 4020, 1635, 6756, 651, 5253, 2545, 6214, 966, 5253, 3160, 1357, 6040, 2545, 6214, 182, 0, 589, 2644, 6315, 3383, 4392, 2770, 406, 3769, 182, 2659, 998, 868, 1338, 719, 6315, 6756, 1534, 1588, 6007, 6009, 6802, 1338, 6573, 1367, 6756, 1534, 1588, 2288, 2494, 966, 6315, 287, 5988, 911, 6009, 6802, 723, 3556, 651, 3648, 723, 2065, 2654, 3903, 2994, 3630, 1338, 1363, 182, 0, 589, 2644, 463, 4669, 406, 3769, 182, 2659, 998, 868, 2276, 2223, 32, 12, 3020, 1297, 785, 280, 4377, 2178, 4793, 3903, 2000, 2002, 4669, 2327, 376, 1367, 6756, 5528, 228, 5738, 3020, 5983, 966, 5528, 4934, 5738, 3020, 5983, 504, 3903, 782, 6573, 6817, 1338, 719, 1192, 3022, 765, 4084, 2178, 4793, 2118, 2002, 4669, 2327, 1591, 1367, 6756, 3903, 2008, 5169, 3900, 966, 3900, 5169, 3900, 911, 6009, 182, 0, 589, 2644, 1338, 1903, 566, 3827, 406, 3769, 182, 2659, 998, 4719, 2377, 6573, 2954, 1809, 1635, 6756, 1622, 5253, 242, 4084, 4352, 3903, 3246, 6276, 5843, 1853, 966, 2223, 398, 1913, 2157, 4463, 4702, 3903, 6009, 6802, 451, 5801, 30, 4463, 4702, 850, 2223, 830, 684, 3383, 891, 3903, 659, 5296, 1338, 2974, 6802, 1338, 719, 1830, 6756, 4716, 4761, 2288, 2494, 6817, 1338, 1903, 1635, 6756, 4760, 4747, 1770, 1175, 4463, 4702, 902, 1175, 6666, 4435, 4463, 4702, 3903, 4719, 715, 182, 0, 589, 2644, 2223, 3418, 406, 3769, 182, 2659, 998, 4719, 2217, 680, 1778, 5531, 3092, 2178, 4793, 1635, 6756, 4635, 1866, 4687, 4688, 6802, 2217, 680, 5358, 842, 4993, 4715, 2178, 4793, 3903, 1367, 6756, 5640, 4687, 4688, 843, 1367, 6756, 2820, 3680, 4661, 4872, 4687, 3903, 1913, 2157, 6802, 274, 4719, 2217, 680, 4584, 3778, 1297, 4437, 4500, 4392, 2178, 4793, 4760, 4747, 3254, 651, 3212, 242, 3900, 4463, 4702, 2008, 2494, 3903, 1338, 1363, 182, 0, 0, 6362, 1355, 2520, 4955, 3556, 6798, 3778, 4346, 6799, 11, 1208, 1594, 1297, 2659, 4955, 3556, 3939, 1908, 6798, 16, 14, 15, 16, 6799, 0, 0, 5269, 3009, 592, 5253, 181, 5483, 4471, 2953, 1803, 6802, 3769, 288, 2643, 4471, 219, 5483, 181, 4471, 2654, 4760, 3853, 0, 1537, 1412, 4144, 3769, 182, 0, 0, 1537, 1412, 4144, 3769, 182, 0, 0, 1408, 2708, 2646, 3769, 354, 400, 588, 332, 4955, 998, 5474, 934, 4017, 776, 1788, 2161, 4955, 1788, 6802, 759, 2274, 354, 400, 327, 4955, 2177, 181, 5634, 1784, 2161, 463, 516, 998, 1055, 1845, 5574, 278, 3903, 6362, 1355, 2520, 4955, 998, 182, 0, 2659, 4955, 596, 2178, 911, 315, 840, 181, 3900, 4848, 6802, 846, 5112, 4858, 6802, 1959, 220, 911, 5112, 4858, 3903, 4955, 3556, 889, 3769, 182, 0, 2659, 4955, 596, 2178, 911, 3761, 4934, 6802, 846, 3761, 5860, 181, 1367, 2166, 181, 3186, 5118, 181, 4862, 4867, 6802, 1959, 220, 911, 3761, 5860, 181, 1367, 2166, 181, 3186, 5118, 181, 4862, 4867, 3903, 4955, 3556, 889, 3769, 182, 2646, 4955, 2654, 6214, 5887, 566, 220, 3765, 622, 181, 5772, 5776, 181, 4946, 4751, 3092, 4762, 181, 219, 2560, 3191, 765, 6462, 998, 889, 3769, 6802, 2159, 3449, 5968, 6802, 343, 6249, 724, 3285, 765, 3457, 6802, 719, 6007, 3843, 2065, 182, 2646, 4955, 2654, 6214, 219, 1577, 1096, 4926, 966, 882, 5013, 796, 6802, 219, 1577, 889, 2545, 2646, 3769, 293, 3407, 4720, 181, 3902, 4940, 2161, 588, 680, 688, 182, 776, 1788, 966, 4955, 1788, 868, 4719, 1622, 2646, 3769, 889, 318, 260, 6666, 3900, 642, 247, 6798, 857, 2646, 3212, 6799, 1842, 3115, 2098, 286, 6413, 589, 2644, 2636, 1363, 3903, 466, 2031, 182, 0, 0, 247, 688, 7, 1367, 5200, 247, 4946, 4751, 3092, 4762, 181, 219, 2560, 3191, 765, 6462, 998, 889, 3769, 6802, 2159, 3449, 5968, 6802, 343, 6249, 724, 3285, 765, 3457, 6802, 719, 6007, 3843, 2065, 182, 2646, 4955, 2654, 6214, 219, 1577, 1096, 4926, 966, 882, 5013, 796, 6802, 219, 1577, 889, 2545, 2646, 3769, 293, 3407, 4720, 181, 3902, 4940, 2161, 588, 680, 688, 182, 776, 1788, 966, 4955, 1788, 868, 4719, 1622, 2646, 3769, 889, 318, 260, 6666, 3900, 642, 247, 6798, 857, 2646, 3212, 6799, 1842, 3115, 2098, 286, 6413, 589, 2644, 2636, 1363, 3903, 466, 2031, 182, 0]\n",
      "['<PAD>', '具', '有', '促', '进', '造', '血', '和', '止', '血', '作', '用', '。', '本', '品', '能', '促', '进', '环', '磷', '酰', '胺', '所', '致', '白', '细', '胞', '总', '数', '下', '降', '的', '恢', '复', '，', '提', '高', '失', '血', '小', '鼠', '的', '血', '红', '蛋', '白', '含', '量', '，', '缩', '短', '小', '鼠', '出', '血', '时', '间', '和', '血', '浆', '复', '钙', '时', '间', '。', '<PAD>', '具', '有', '雌', '激', '素', '样', '作', '用', '。', '本', '品', '可', '增', '加', '雌', '鼠', '子', '宫', '重', '量', '，', '增', '高', '大', '鼠', '子', '宫', '指', '数', '和', '雌', '二', '醇', '含', '量', '，', '动', '物', '出', '现', '动', '情', '期', '的', '比', '率', '增', '多', '。', '<PAD>', '具', '有', '保', '肝', '作', '用', '。', '本', '品', '可', '拮', '抗', 'D', '-', '氨', '基', '半', '乳', '糖', '所', '致', '的', '急', '性', '肝', '损', '伤', '大', '鼠', '谷', '丙', '转', '氨', '酶', '和', '谷', '草', '转', '氨', '酶', '值', '的', '升', '高', '；', '增', '加', '四', '氯', '化', '碳', '所', '致', '慢', '性', '肝', '损', '害', '大', '鼠', '的', '总', '蛋', '白', '和', '白', '蛋', '白', '含', '量', '。', '<PAD>', '具', '有', '增', '强', '免', '疫', '作', '用', '。', '本', '品', '能', '提', '高', '正', '常', '小', '鼠', '对', '血', '中', '碳', '粒', '的', '清', '除', '速', '度', '和', '抗', '体', '形', '成', '细', '胞', '的', '量', '，', '促', '进', 'B', '细', '胞', '受', '抗', '原', '刺', '激', '后', '的', '分', '裂', '增', '殖', '，', '增', '加', '幼', '鼠', '胸', '腺', '指', '数', '；', '增', '强', '小', '鼠', '腹', '腔', '巨', '噬', '细', '胞', '吞', '噬', '鸡', '红', '细', '胞', '的', '能', '力', '。', '<PAD>', '具', '有', '抗', '炎', '作', '用', '。', '本', '品', '能', '抑', '制', '巴', '豆', '油', '所', '致', '小', '鼠', '耳', '廓', '肿', '胀', '，', '抑', '制', '角', '叉', '菜', '胶', '所', '致', '的', '大', '鼠', '足', '肿', '胀', '及', '大', '鼠', '棉', '球', '肉', '芽', '肿', '的', '形', '成', '，', '也', '能', '抑', '制', '羧', '甲', '基', '纤', '维', '素', '所', '致', '腹', '腔', '渗', '出', '液', '中', '白', '细', '胞', '总', '数', '的', '增', '多', '。', '<PAD>', '<PAD>', '吉', '林', '一', '正', '药', '业', '集', '团', '有', '限', '公', '司', '<PAD>', '<PAD>', '补', '气', '养', '血', '，', '调', '经', '止', '带', '。', '用', '于', '气', '血', '两', '虚', '，', '身', '体', '瘦', '弱', '，', '腰', '膝', '酸', '软', '，', '月', '经', '量', '少', '、', '后', '错', '，', '带', '下', '<PAD>', '吉', '林', '一', '正', '药', '业', '集', '团', '有', '限', '公', '司', '<PAD>', '<PAD>', '口', '服', '。', '一', '次', '9', '克', '，', '一', '日', '1', '次', '；', '或', '将', '药', '丸', '加', '适', '量', '开', '水', '溶', '后', '服', '。', '<PAD>', '<PAD>', '丸', '剂', '(', '大', '蜜', '丸', ')', '<PAD>', '<PAD>', '孕', '妇', '禁', '用', '。', '<PAD>', '<PAD>', '大', '蜜', '丸', '每', '丸', '重', '9', '克', '<PAD>', '<PAD>', '在', '服', '用', '本', '品', '期', '间', '，', '如', '果', '感', '到', '不', '适', '，', '要', '尽', '快', '告', '诉', '医', '师', '或', '药', '师', '。', '情', '况', '紧', '急', '可', '先', '停', '止', '使', '用', '，', '必', '要', '时', '到', '医', '院', '就', '诊', '。', '<PAD>', '目', '前', '尚', '未', '检', '索', '到', '本', '品', '的', '不', '良', '反', '应', '。', '<PAD>', '<PAD>', '具', '有', '促', '进', '造', '血', '和', '止', '血', '作', '用', '。', '本', '品', '能', '促', '进', '环', '磷', '酰', '胺', '所', '致', '白', '细', '胞', '总', '数', '下', '降', '的', '恢', '复', '，', '提', '高', '失', '血', '小', '鼠', '的', '血', '红', '蛋', '白', '含', '量', '，', '缩', '短', '小', '鼠', '出', '血', '时', '间', '和', '血', '浆', '复', '钙', '时', '间', '。', '<PAD>', '具', '有', '雌', '激', '素', '样', '作', '用', '。', '本', '品', '可', '增', '加', '雌', '鼠', '子', '宫', '重', '量', '，', '增', '高', '大', '鼠', '子', '宫', '指', '数', '和', '雌', '二', '醇', '含', '量', '，', '动', '物', '出', '现', '动', '情', '期', '的', '比', '率', '增', '多', '。', '<PAD>', '具', '有', '保', '肝', '作', '用', '。', '本', '品', '可', '拮', '抗', 'D', '-', '氨', '基', '半', '乳', '糖', '所', '致', '的', '急', '性', '肝', '损', '伤', '大', '鼠', '谷', '丙', '转', '氨', '酶', '和', '谷', '草', '转', '氨', '酶', '值', '的', '升', '高', '；', '增', '加', '四', '氯', '化', '碳', '所', '致', '慢', '性', '肝', '损', '害', '大', '鼠', '的', '总', '蛋', '白', '和', '白', '蛋', '白', '含', '量', '。', '<PAD>', '具', '有', '增', '强', '免', '疫', '作', '用', '。', '本', '品', '能', '提', '高', '正', '常', '小', '鼠', '对', '血', '中', '碳', '粒', '的', '清', '除', '速', '度', '和', '抗', '体', '形', '成', '细', '胞', '的', '量', '，', '促', '进', 'B', '细', '胞', '受', '抗', '原', '刺', '激', '后', '的', '分', '裂', '增', '殖', '，', '增', '加', '幼', '鼠', '胸', '腺', '指', '数', '；', '增', '强', '小', '鼠', '腹', '腔', '巨', '噬', '细', '胞', '吞', '噬', '鸡', '红', '细', '胞', '的', '能', '力', '。', '<PAD>', '具', '有', '抗', '炎', '作', '用', '。', '本', '品', '能', '抑', '制', '巴', '豆', '油', '所', '致', '小', '鼠', '耳', '廓', '肿', '胀', '，', '抑', '制', '角', '叉', '菜', '胶', '所', '致', '的', '大', '鼠', '足', '肿', '胀', '及', '大', '鼠', '棉', '球', '肉', '芽', '肿', '的', '形', '成', '，', '也', '能', '抑', '制', '羧', '甲', '基', '纤', '维', '素', '所', '致', '腹', '腔', '渗', '出', '液', '中', '白', '细', '胞', '总', '数', '的', '增', '多', '。', '<PAD>', '<PAD>', '非', '处', '方', '药', '物', '（', '甲', '类', '）', ',', '国', '家', '基', '本', '药', '物', '目', '录', '（', '2', '0', '1', '2', '）', '<PAD>', '<PAD>', '补', '气', '养', '血', '、', '调', '经', '止', '带', '，', '用', '于', '月', '经', '不', '调', '、', '经', '期', '腹', '痛', '<PAD>', '孕', '妇', '禁', '用', '。', '<PAD>', '<PAD>', '孕', '妇', '禁', '用', '。', '<PAD>', '<PAD>', '如', '果', '服', '用', '任', '何', '其', '他', '药', '品', '请', '告', '知', '医', '师', '或', '药', '师', '，', '包', '括', '任', '何', '从', '药', '房', '、', '超', '市', '或', '保', '健', '品', '商', '店', '购', '买', '的', '非', '处', '方', '药', '品', '。', '<PAD>', '本', '药', '内', '所', '含', '人', '参', '、', '白', '芍', '，', '反', '藜', '芦', '，', '忌', '与', '含', '藜', '芦', '的', '药', '物', '同', '用', '。', '<PAD>', '本', '药', '内', '所', '含', '甘', '草', '，', '反', '甘', '遂', '、', '大', '戟', '、', '海', '藻', '、', '芫', '花', '，', '忌', '与', '含', '甘', '遂', '、', '大', '戟', '、', '海', '藻', '、', '芫', '花', '的', '药', '物', '同', '用', '。', '服', '药', '期', '间', '避', '免', '与', '生', '冷', '、', '辛', '辣', '、', '荤', '腥', '油', '腻', '、', '不', '易', '消', '化', '食', '品', '同', '用', '，', '戒', '烟', '酒', '，', '以', '防', '助', '湿', '化', '热', '，', '加', '重', '病', '情', '。', '服', '药', '期', '间', '不', '宜', '喝', '茶', '和', '吃', '萝', '卜', '，', '不', '宜', '同', '时', '服', '用', '五', '灵', '脂', '、', '皂', '荚', '或', '其', '制', '剂', '。', '医', '师', '和', '药', '师', '可', '能', '对', '服', '用', '同', '仁', '乌', '鸡', '白', '凤', '丸', '（', '口', '服', '液', '）', '应', '注', '意', '事', '项', '具', '有', '更', '多', '的', '信', '息', '。', '<PAD>', '<PAD>', '丸', '剂', '(', '大', '蜜', '丸', '荤', '腥', '油', '腻', '、', '不', '易', '消', '化', '食', '品', '同', '用', '，', '戒', '烟', '酒', '，', '以', '防', '助', '湿', '化', '热', '，', '加', '重', '病', '情', '。', '服', '药', '期', '间', '不', '宜', '喝', '茶', '和', '吃', '萝', '卜', '，', '不', '宜', '同', '时', '服', '用', '五', '灵', '脂', '、', '皂', '荚', '或', '其', '制', '剂', '。', '医', '师', '和', '药', '师', '可', '能', '对', '服', '用', '同', '仁', '乌', '鸡', '白', '凤', '丸', '（', '口', '服', '液', '）', '应', '注', '意', '事', '项', '具', '有', '更', '多', '的', '信', '息', '。', '<PAD>']\n",
      "[0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 0, 0, 10, 10, 10, 10, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 0, 0, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 7, 7, 0, 0, 0, 7, 7, 0, 7, 7, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['O', 'O', 'O', 'O', 'O', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'O', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'O', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'O', 'O', 'O', 'SYNDROME', 'SYNDROME', 'SYNDROME', 'SYNDROME', 'O', 'O', 'O', 'O', 'O', 'O', 'SYMPTOM', 'SYMPTOM', 'SYMPTOM', 'SYMPTOM', 'O', 'SYMPTOM', 'SYMPTOM', 'SYMPTOM', 'SYMPTOM', 'O', 'O', 'O', 'O', 'SYMPTOM', 'SYMPTOM', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DRUG_DOSAGE', 'DRUG_DOSAGE', 'DRUG_DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'O', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'DRUG_EFFICACY', 'O', 'O', 'O', 'SYMPTOM', 'SYMPTOM', 'SYMPTOM', 'SYMPTOM', 'O', 'O', 'O', 'O', 'O', 'O', 'PERSON_GROUP', 'PERSON_GROUP', 'O', 'O', 'O', 'O', 'O', 'PERSON_GROUP', 'PERSON_GROUP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'O', 'O', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'FOOD_GROUP', 'FOOD_GROUP', 'O', 'FOOD_GROUP', 'FOOD_GROUP', 'O', 'O', 'O', 'FOOD_GROUP', 'FOOD_GROUP', 'O', 'FOOD_GROUP', 'FOOD_GROUP', 'FOOD_GROUP', 'FOOD_GROUP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'DRUG_INGREDIENT', 'DRUG_INGREDIENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DRUG_DOSAGE', 'DRUG_DOSAGE', 'DRUG_DOSAGE', 'FOOD_GROUP', 'FOOD_GROUP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(train_datas[50])\n",
    "print([idx2vocab[idx] for idx in train_datas[50]])\n",
    "print(train_labels[50])\n",
    "print([idx2label[idx] for idx in train_labels[50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "6874 11\n",
      "padding sequences\n",
      "x_train shape: (1000, 500)\n",
      "x_test shape: (1000, 500)\n",
      "trainlabels shape: (1000, 500, 11)\n",
      "testlabels shape: (1000, 500, 11)\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 500, 32)           219968    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 500, 32)           6272      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 500, 11)           363       \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 500, 11)           275       \n",
      "=================================================================\n",
      "Total params: 226,878\n",
      "Trainable params: 226,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/apple/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "900/900 [==============================] - 31s 35ms/step - loss: 6.5872 - crf_viterbi_accuracy: 0.2925 - val_loss: 4.7993 - val_crf_viterbi_accuracy: 0.4587\n",
      "Epoch 2/30\n",
      "900/900 [==============================] - 26s 29ms/step - loss: 5.4632 - crf_viterbi_accuracy: 0.6604 - val_loss: 3.9309 - val_crf_viterbi_accuracy: 0.8326\n",
      "Epoch 3/30\n",
      "900/900 [==============================] - 30s 33ms/step - loss: 5.1125 - crf_viterbi_accuracy: 0.8140 - val_loss: 3.8042 - val_crf_viterbi_accuracy: 0.8326\n",
      "Epoch 4/30\n",
      "900/900 [==============================] - 29s 32ms/step - loss: 5.0193 - crf_viterbi_accuracy: 0.8141 - val_loss: 3.7059 - val_crf_viterbi_accuracy: 0.8325\n",
      "Epoch 5/30\n",
      "900/900 [==============================] - 28s 31ms/step - loss: 4.9222 - crf_viterbi_accuracy: 0.8138 - val_loss: 3.6178 - val_crf_viterbi_accuracy: 0.8325\n",
      "Epoch 6/30\n",
      "900/900 [==============================] - 25s 28ms/step - loss: 4.8454 - crf_viterbi_accuracy: 0.8139 - val_loss: 3.5579 - val_crf_viterbi_accuracy: 0.8333\n",
      "Epoch 7/30\n",
      "900/900 [==============================] - 28s 31ms/step - loss: 4.7774 - crf_viterbi_accuracy: 0.8177 - val_loss: 3.5066 - val_crf_viterbi_accuracy: 0.8374\n",
      "Epoch 8/30\n",
      "900/900 [==============================] - 25s 28ms/step - loss: 4.7160 - crf_viterbi_accuracy: 0.8265 - val_loss: 3.4625 - val_crf_viterbi_accuracy: 0.8417\n",
      "Epoch 9/30\n",
      "900/900 [==============================] - 26s 29ms/step - loss: 4.6646 - crf_viterbi_accuracy: 0.8360 - val_loss: 3.4285 - val_crf_viterbi_accuracy: 0.8480\n",
      "Epoch 10/30\n",
      "900/900 [==============================] - 33s 37ms/step - loss: 4.6249 - crf_viterbi_accuracy: 0.8438 - val_loss: 3.4035 - val_crf_viterbi_accuracy: 0.8521\n",
      "Epoch 11/30\n",
      "900/900 [==============================] - 33s 37ms/step - loss: 4.5925 - crf_viterbi_accuracy: 0.8504 - val_loss: 3.3806 - val_crf_viterbi_accuracy: 0.8581\n",
      "Epoch 12/30\n",
      "900/900 [==============================] - 25s 28ms/step - loss: 4.5635 - crf_viterbi_accuracy: 0.8570 - val_loss: 3.3549 - val_crf_viterbi_accuracy: 0.8638\n",
      "Epoch 13/30\n",
      "900/900 [==============================] - 23s 25ms/step - loss: 4.5363 - crf_viterbi_accuracy: 0.8617 - val_loss: 3.3356 - val_crf_viterbi_accuracy: 0.8664\n",
      "Epoch 14/30\n",
      "900/900 [==============================] - 24s 27ms/step - loss: 4.5128 - crf_viterbi_accuracy: 0.8653 - val_loss: 3.3178 - val_crf_viterbi_accuracy: 0.8699\n",
      "Epoch 15/30\n",
      "900/900 [==============================] - 25s 27ms/step - loss: 4.4908 - crf_viterbi_accuracy: 0.8715 - val_loss: 3.2990 - val_crf_viterbi_accuracy: 0.8745\n",
      "Epoch 16/30\n",
      "900/900 [==============================] - 26s 29ms/step - loss: 4.4713 - crf_viterbi_accuracy: 0.8759 - val_loss: 3.2817 - val_crf_viterbi_accuracy: 0.8777\n",
      "Epoch 17/30\n",
      "900/900 [==============================] - 26s 29ms/step - loss: 4.4530 - crf_viterbi_accuracy: 0.8808 - val_loss: 3.2681 - val_crf_viterbi_accuracy: 0.8823\n",
      "Epoch 18/30\n",
      "900/900 [==============================] - 25s 28ms/step - loss: 4.4372 - crf_viterbi_accuracy: 0.8854 - val_loss: 3.2545 - val_crf_viterbi_accuracy: 0.8860\n",
      "Epoch 19/30\n",
      "900/900 [==============================] - 24s 27ms/step - loss: 4.4229 - crf_viterbi_accuracy: 0.8893 - val_loss: 3.2439 - val_crf_viterbi_accuracy: 0.8895\n",
      "Epoch 20/30\n",
      "900/900 [==============================] - 25s 27ms/step - loss: 4.4107 - crf_viterbi_accuracy: 0.8922 - val_loss: 3.2328 - val_crf_viterbi_accuracy: 0.8908\n",
      "Epoch 21/30\n",
      "288/900 [========>.....................] - ETA: 15s - loss: 4.8226 - crf_viterbi_accuracy: 0.8934"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Masking, Embedding, Bidirectional, LSTM, Dense, Input, TimeDistributed, Activation\n",
    "from keras.preprocessing import sequence\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras_contrib.metrics import crf_viterbi_accuracy\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "EMBED_DIM = 32\n",
    "HIDDEN_SIZE = 16\n",
    "MAX_LEN = 500\n",
    "VOCAB_SIZE = len(vocab2idx)\n",
    "CLASS_NUMS = len(label2idx)\n",
    "print(VOCAB_SIZE, CLASS_NUMS)\n",
    "\n",
    "print('padding sequences')\n",
    "train_datas = sequence.pad_sequences(train_datas, maxlen=MAX_LEN)\n",
    "train_labels = sequence.pad_sequences(train_labels, maxlen=MAX_LEN)\n",
    "test_datas = sequence.pad_sequences(test_datas, maxlen=MAX_LEN)\n",
    "test_labels = sequence.pad_sequences(test_labels, maxlen=MAX_LEN)\n",
    "print('x_train shape:', train_datas.shape)\n",
    "print('x_test shape:', test_datas.shape)\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, CLASS_NUMS)\n",
    "test_labels = keras.utils.to_categorical(test_labels, CLASS_NUMS)\n",
    "print('trainlabels shape:', train_labels.shape)\n",
    "print('testlabels shape:', test_labels.shape)\n",
    "\n",
    "## BiLSTM+CRF模型构建\n",
    "inputs = Input(shape=(MAX_LEN,), dtype='int32')\n",
    "x = Masking(mask_value=0)(inputs)\n",
    "x = Embedding(VOCAB_SIZE, EMBED_DIM, mask_zero=True)(x)\n",
    "x = Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True))(x)\n",
    "x = TimeDistributed(Dense(CLASS_NUMS))(x)\n",
    "outputs = CRF(CLASS_NUMS)(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=crf_loss, optimizer='adam', metrics=[crf_viterbi_accuracy])\n",
    "model.fit(train_datas, train_labels, epochs=EPOCHS, verbose=1, validation_split=0.1)\n",
    "\n",
    "score = model.evaluate(test_datas, test_labels, batch_size=BATCH_SIZE)\n",
    "print(model.metrics_names)\n",
    "print(score)\n",
    "\n",
    "# save model\n",
    "model.save(\"./model/ch_ner_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 500\n",
    "sentence = \" 北京同仁堂科技发展股份有限公司制药厂  1.忌食辛辣，少进油腻。 2.感冒发热病人不宜服用。 3.有高血压、心脏病、肝病、糖尿病、肾病等慢性病严重者应在医师指导下服用。 4.伴有月经紊乱者，应在医师指导下服用。 5.眩晕症状较重者，应及时去医院就诊。 6.服药2周症状无缓解，应去医院就诊。 7.对本品过敏者禁用，过敏体质者慎用。 8.本品性状发生改变时禁止使用。 9.请将本品放在儿童不能接触的地方。 10.如正在使用其他药品，使用本品前请咨询医师或药师。  本品为浅黄色至棕黄色颗粒，气微香，味微苦。  滋养肝肾、宁心安神。用于更年期综合症属阴虚肝旺症，症见烘热汗出，头晕耳鸣，失眠多梦，五心烦热，腰背酸痛，大便干燥，心烦易怒，舌红少苔，脉弦细或弦细 开水冲服。一次1袋(12g)，一日3次。  如与其他药物同时使用可能会发生药物相互作用，详情请咨询医师或药师。  12g*10袋/盒  用于更年期综合症属阴虚肝旺症  铝塑复合膜包装，每袋装12克，每盒装10袋。  非处方药物（甲类）,中药保护品种二级  12g*10袋/盒  用于更年期综合症属阴虚肝旺更年期综合症气微香，味微苦。\"\n",
    "\n",
    "sent_chars = list(sentence)\n",
    "sent2id = [vocab2idx[word] if word in vocab2idx else vocab2idx['<UNK>'] for word in sent_chars]\n",
    "\n",
    "sent2id_new = np.array([[0] * (maxlen-len(sent2id)) + sent2id[:maxlen]])\n",
    "y_pred = model.predict(sent2id_new)\n",
    "y_label = np.argmax(y_pred, axis=2)\n",
    "y_label = y_label.reshape(1, -1)[0]\n",
    "y_ner = [idx2label[i] for i in y_label][-len(sent_chars):]\n",
    "\n",
    "print(idx2label)\n",
    "print(sent_chars)\n",
    "print(sent2id)\n",
    "print(y_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(sent_chars,y_ner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
